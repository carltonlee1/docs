---
title: "Introduction"
description: "Intelligent LLM routing service with privacy-first design"
---

## Welcome to Pathfinder

Pathfinder is an intelligent API that routes prompts to the optimal language model based on cost, capability, and performance. Instead of choosing a model yourself, send your prompt to Pathfinder and it automatically recommends the best model and provider for your use case.

<Card
  title="Get Started"
  icon="rocket"
  href="/pathfinder/getting-started/quickstart"
  horizontal
>
  Make your first routing decision in 5 minutes.
</Card>

## Key Benefits

<Columns cols={2}>
  <Card
    title="Cost Optimization"
    icon="piggy-bank"
  >
    Save up to 70% on API costs by routing to cheaper models without sacrificing quality.
  </Card>
  <Card
    title="Privacy First"
    icon="shield-halved"
  >
    Your raw prompts are never stored—only anonymized hashes and features.
  </Card>
  <Card
    title="Automatic Failover"
    icon="arrows-rotate"
  >
    If your preferred provider is down, Pathfinder routes to a backup automatically.
  </Card>
  <Card
    title="Real-Time Insights"
    icon="chart-line"
  >
    Track which models work best for your use cases with analytics.
  </Card>
</Columns>

## Explore the Docs

<Columns cols={2}>
  <Card
    title="Quickstart Guide"
    icon="bolt"
    href="/pathfinder/getting-started/quickstart"
  >
    Get your first routing decision in minutes.
  </Card>
  <Card
    title="API Reference"
    icon="code"
    href="/pathfinder/endpoints/routing-decision"
  >
    Explore the REST and gRPC APIs.
  </Card>
  <Card
    title="SDKs"
    icon="toolbox"
    href="/pathfinder/sdks/index"
  >
    Python, TypeScript, and CLI libraries.
  </Card>
  <Card
    title="Core Concepts"
    icon="lightbulb"
    href="/pathfinder/core-concepts/routing-decisions"
  >
    Learn how routing decisions work.
  </Card>
</Columns>

## How It Works

```
1. You send a prompt → 2. Pathfinder analyzes it → 3. Returns best model/provider → 4. You execute with that provider
```

Pathfinder decides which model to use, but you execute the actual completion with that provider's API.
